{"nbformat_minor": 1, "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "version": "3.6.4", "name": "python", "file_extension": ".py"}}, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "e81ee64d-e474-4662-9036-ce23df615199", "_uuid": "b6269c0e8f417f82daf093dda8fa0da6d2c57d86"}, "source": ["# Introduction\n", "**This will be your workspace for Kaggle's Machine Learning education track.**\n", "\n", "You will build and continually improve a model to predict housing prices as you work through each tutorial.  Fork this notebook and write your code in it.\n", "\n", "The data from the tutorial, the Melbourne data, is not available in this workspace.  You will need to translate the concepts to work with the data in this notebook, the Iowa data.\n", "\n", "Come to the [Learn Discussion](https://www.kaggle.com/learn-forum) forum for any questions or comments. \n", "\n", "# Write Your Code Below\n", "\n"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "86b26423-563a-4fa1-a595-89e25ff93089", "_uuid": "1c728098629e1301643443b1341556a15c089b2b"}, "source": ["import pandas as pd\n", "\n", "# saving file path of lowa data in main_file_path\n", "lowa_file_path = '../input/train.csv'\n", "# reading and storing the data in DataFrame \n", "lowa_data = pd.read_csv(lowa_file_path)\n", "# print summary of lowa data\n", "print(lowa_data.describe())"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "9ab512bb-210c-4cb3-821c-4243801cc7e1", "_uuid": "f49143097d64df4963fc945050ae89a7b2fbbd75"}, "source": ["# print column names present in lowa_data\n", "print(lowa_data.columns)"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "33742aec-068e-492f-9622-88d4a9dba908", "_uuid": "c3a299ee71feed9b1f87db9a48118ee237f6af11"}, "source": ["# lowa_data SalePrice of house \n", "lowa_price_data = lowa_data.SalePrice\n", "# print few rows from lowa_data's SalePrice column.  This is a Series\n", "print(lowa_price_data.head())"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "78d26b52-411d-428c-833b-ac0ce19c5278", "_uuid": "b333e8454621b4f5b3b1b38cd426088d4eb131cc"}, "source": ["# describe any two columns from lowa_data and store it in a DataFrame\n", "columns_of_interest = ['LotArea', 'SalePrice']\n", "two_columns_of_data = lowa_data[columns_of_interest]\n", "\n", "print(two_columns_of_data.describe())"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "a1fb0662-418c-4c2a-97bd-cdd5c4d539f0", "_uuid": "972530a40f51bc2c75027dd06ca9981139edbe73"}, "source": ["# My first use of Scikit Learn Library.\n", "# Step 1: Choosing the prediction target.  Here I am selecting the SalePrice\n", "# By convention the prediction target will be called 'y' (without quotes).  Here we are going to predict the SalePrice.  Just assign it to 'y'\n", "y = lowa_data.SalePrice\n", "\n", "# Step 2: Now choose the predictors.  Here we use only numerical predictors.  But we can use any predictors.  By convention the predictors will be called 'X'.  It is a DataFrame\n", "lowa_predictors = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n", "X = lowa_data[lowa_predictors]\n", "\n", "# Step 3: Define a model.  Step 4: Fit the model\n", "from sklearn.tree import DecisionTreeRegressor\n", "\n", "# Define model\n", "lowa_model = DecisionTreeRegressor()\n", "\n", "# Fit model\n", "lowa_model.fit(X, y)\n"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "0b41408c-2e28-4c98-bb05-e24b20cbb7c5", "_uuid": "68a59118ac08eaa9d89a2ef835b144ab720c57de"}, "source": ["# Step 5: Predict for some of the first few rows of X\n", "print(\"Making predictions for the following 5 houses:\")\n", "print(X.head())\n", "print(\"The predictions are\")\n", "print(lowa_model.predict(X.head()))\n", "# print(y.head()) Checking if the value of the predictions and the actual values are same or not -> This step is not essential"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "4420220c-969d-47fb-bab9-91da3302fb53", "_uuid": "fee804dc4e4b36fcf0a7bb388a5089f2e9529e66"}, "source": ["# use train_test_split function to split up data\n", "from sklearn.model_selection import train_test_split\n", "\n", "# split data into training and validation data, for both predictors and target\n", "# The split is based on a random number generator. Supplying a numeric value to\n", "# the random_state argument guarantees we get the same split every time we\n", "# run this script.\n", "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n", "# fit our model with the new data\n", "lowa_model.fit(train_X, train_y)\n", "\n", "# get predicted prices on validation data\n", "val_predictions = lowa_model.predict(val_X)\n", "\n", "# calculation of mean absoulute error (MAE).  The formula for MAE is 'error = actual - predicted'.  The error will be converted to a positive value even if it is negative.  And it's mean is MAE.\n", "from sklearn.metrics import mean_absolute_error\n", "\n", "print(\"The MAE for our model using Decision Tree algorithm is: \" + str(mean_absolute_error(val_y, val_predictions)))"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "8e345afc-a64f-4ecf-85ee-0f353cb2cd26", "_uuid": "8b88fe5597d6b64e5aed5caf737439884ba3146f", "collapsed": true}, "source": ["def get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n", "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n", "    model.fit(predictors_train, targ_train)\n", "    preds_val = model.predict(predictors_val)\n", "    mae = mean_absolute_error(targ_val, preds_val)\n", "    return(mae)"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "be6cdbb4-e9d5-40c7-af16-235a8924fde5", "_uuid": "e3032205224f88ce93fcae686fdf96209275d6df"}, "source": ["# compare MAE with differing values of max_leaf_nodes\n", "for max_leaf_nodes in [2, 5, 10, 20, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 50, 500, 5000]:\n", "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n", "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"], "execution_count": null}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "3d594d42-2099-40d3-8152-42b4b25dd2d7", "_uuid": "ef3777f65a185671e559b6855d9fa610daf328e6"}, "source": ["# Using a sophisticated Machine Learning algorithm 'Random Forests'\n", "from sklearn.ensemble import RandomForestRegressor\n", "\n", "# same steps as like DecisionTree\n", "lowa_forest_model = RandomForestRegressor()\n", "lowa_forest_model.fit(train_X, train_y)\n", "lowa_preds = lowa_forest_model.predict(val_X)\n", "print(\"The MAE using Random Forests algorithm is: \" + str(mean_absolute_error(val_y, lowa_preds)))"], "execution_count": null}], "nbformat": 4}